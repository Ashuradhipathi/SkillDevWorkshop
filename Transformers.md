[pytorch rnn](https://jaketae.github.io/study/pytorch-rnn/)
<br>
[lstm](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
<br>
[word2vec](https://jalammar.github.io/illustrated-word2vec/))
<br>

[Seq2Seq](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)
---
[transfrormer](https://jalammar.github.io/illustrated-transformer/)
<br>
[bert](https://jalammar.github.io/illustrated-bert/)
<br>
[attention forms](https://towardsdatascience.com/attention-and-its-different-forms-7fc3674d14dc)
<br>
---
[tensor flow attentions](https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/)
<br>
[Attention](https://nlp.seas.harvard.edu/2018/04/03/attention.html)

---
[pytorch tutorials](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)
